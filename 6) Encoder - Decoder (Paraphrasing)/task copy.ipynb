{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построить нейронную сеть по архитектуре ***Encoder – Decoder***, что должна переводить токсичные комменты в нетоксичные (***Paraphrasing***/***Translation***).\n",
    "* В архитектуре сети обязательно использование слоя эмбеддинга и LSTM (реализация с помощью ***Keras***)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Настройки/Импорты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Версии важных модулей:\n",
    "* pandas==2.1.1\n",
    "* numpy==1.26.2\n",
    "* keras==3.3.3\n",
    "* tensorflow==2.16.1 (no GPU)\n",
    "* matplotlib==3.6.2\n",
    "* navec==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # для работы с массивами\n",
    "import pandas as pd # для удобной работы с датасетом\n",
    "\n",
    "import re # для регулярных выражений\n",
    "\n",
    "from nltk.tokenize import word_tokenize # для токенизации строк\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # токенизатор текста (на версии keras 2.15.0 можно было не тягать из tensorflow)\n",
    "from keras.utils import pad_sequences # для приведения векторов токенов к единой размерности\n",
    "from navec import Navec # для русскоязычных эмбеддингов\n",
    "\n",
    "from keras.layers import Input, Dense, Embedding, LSTM # слои для нейронной сети\n",
    "from keras.models import Model # Keras модель (не последовательная)\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping # callback функции\n",
    "import keras # для работы с моделью\n",
    "\n",
    "import matplotlib.pyplot as plt # для построения графиков\n",
    "import time # для отслеживания времени выполнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./data/\" # путь до папки с данными\n",
    "EMBEDDING_DIR = \"./embeddings/\" # путь до папки с эмбеддингами\n",
    "MODELS_DIR = \"./models/\" # путь до папки с моделями\n",
    "RANDOM_STATE = 42 # число для задания случайности\n",
    "DTYPE = np.float32 # используемый тип\n",
    "\n",
    "MAX_WORDS_TOKENIZER = None # ограничение на число слов в словаре токенизатора (None — без ограничения)\n",
    "MAX_LEN = 39 # оптимальное число токенов в документе (если не достаёт — padding, если перебор — truncation), определялось по гистограмме распределения числа токенов в текстах\n",
    "ENCODING_DIM = 256  # итоговая размерность пространства, в которое будет преобразован выход энкодера (такая же размерность входа у декодера)\n",
    "EMBEDDING_DIM = 300 # размерность вектора-эмбеддинга слова\n",
    "\n",
    "EPOCHS_PATIENCE = 50 # число эпох без изменения наблюдаемой метрики, после которого обучение прекратится\n",
    "EPOCHS = 300 # число эпох обучения\n",
    "LEARNING_RATE = 0.001 # learning rate\n",
    "BATCH_SIZE = 10 # размер батча (число сэмплов, передаваемых в модель одновременно => чем больше значение - тем быстрее обучение, но хуже качество из-за аккумуляции градиентов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toxic comment</th>\n",
       "      <th>Polite comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>почитай посты у этого автора, дебил.</td>\n",
       "      <td>попробуйте почитать посты этого автора, может ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>мне жаль тебя, гандон, если для тебя оскорблен...</td>\n",
       "      <td>извините, но мне вас очень жаль, если для вас ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>тебе в говне ходить нормально, урод?</td>\n",
       "      <td>извини, но приятно бы тебе было ходить в грязном?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>блять, я согласен, что энергия от виэ на текущ...</td>\n",
       "      <td>я согласен с вами, что энергия от виэ на текущ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>я этим сраным ватсаппом никогда не пользовался...</td>\n",
       "      <td>просто я, к сожалению, ватсаппом никогда не по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Пошел нахуй с тупичка</td>\n",
       "      <td>Уходите с тупичка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Да уж, ебаные татары русское население мягко г...</td>\n",
       "      <td>Да уж, татары русское население мягко говоря н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Умный дурак в два раза опасней</td>\n",
       "      <td>Умный глупец в два раза опасней</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Это беседа одного того самого имбецила?</td>\n",
       "      <td>Это беседа одного того самого человека?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Да и хер с ними, спорт дерьмо</td>\n",
       "      <td>Да и бог с ними, спорт ужасен</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Toxic comment  \\\n",
       "0                почитай посты у этого автора, дебил.    \n",
       "1    мне жаль тебя, гандон, если для тебя оскорблен...   \n",
       "2                 тебе в говне ходить нормально, урод?   \n",
       "3    блять, я согласен, что энергия от виэ на текущ...   \n",
       "4    я этим сраным ватсаппом никогда не пользовался...   \n",
       "..                                                 ...   \n",
       "194                              Пошел нахуй с тупичка   \n",
       "195  Да уж, ебаные татары русское население мягко г...   \n",
       "196                     Умный дурак в два раза опасней   \n",
       "197            Это беседа одного того самого имбецила?   \n",
       "198                      Да и хер с ними, спорт дерьмо   \n",
       "\n",
       "                                        Polite comment  \n",
       "0    попробуйте почитать посты этого автора, может ...  \n",
       "1    извините, но мне вас очень жаль, если для вас ...  \n",
       "2    извини, но приятно бы тебе было ходить в грязном?  \n",
       "3    я согласен с вами, что энергия от виэ на текущ...  \n",
       "4    просто я, к сожалению, ватсаппом никогда не по...  \n",
       "..                                                 ...  \n",
       "194                                  Уходите с тупичка  \n",
       "195  Да уж, татары русское население мягко говоря н...  \n",
       "196                    Умный глупец в два раза опасней  \n",
       "197            Это беседа одного того самого человека?  \n",
       "198                      Да и бог с ними, спорт ужасен  \n",
       "\n",
       "[199 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_excel(DATA_DIR + \"dataset_200.xls\", index_col=None) # считывание excel данных (index_col — какой столбец из данных использовать как индексы в DataFrame)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление токенов старта и конца."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['почитай посты у этого автора , дебил .',\n",
       " 'мне жаль тебя , гандон , если для тебя оскорбления - норма .',\n",
       " 'тебе в говне ходить нормально , урод ?',\n",
       " 'блять , я согласен , что энергия от виэ на текущий момент дороже . но объясните мне , нахуя правительства всех стран мира стараются развить эту ебанину ? ! нахрена развивать нечто , заведомо убыточное ? !',\n",
       " 'я этим сраным ватсаппом никогда не пользовался , а теперь придется ставить ради одного дебильного турнира . пиздец']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Toxic comment\"] = dataset[\"Toxic comment\"].apply(lambda text: word_tokenize(text)) # разбиваем текст на слова (токены)\n",
    "dataset[\"Toxic comment\"] = dataset[\"Toxic comment\"].apply(lambda sequence: \" \".join(sequence)) # собираем последовательность слов обратно в строку, но теперь даже служебные символы разделены пробелами\n",
    "\n",
    "dataset[\"Polite comment\"] = dataset[\"Polite comment\"].apply(lambda text: word_tokenize(text)) # разбиваем текст на слова (токены)\n",
    "dataset[\"Polite comment\"] = dataset[\"Polite comment\"].apply(lambda sequence: [\"<start>\"] + sequence + [\"<end>\"]) # добавление токенов старта (<start>) и конца (<end>)\n",
    "dataset[\"Polite comment\"] = dataset[\"Polite comment\"].apply(lambda sequence: \" \".join(sequence)) # собираем последовательность слов обратно в строку, но теперь даже служебные символы разделены пробелами\n",
    "\n",
    "texts = dataset[\"Toxic comment\"].tolist() + dataset[\"Polite comment\"].tolist() # собираем все текста в один список\n",
    "texts[:5] # пример первых пяти получившихся элементов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конвертация строк (документов) в последовательности токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_WORDS_TOKENIZER, filters='', lower=True, split=\" \", char_level=False, oov_token='<OOV>') # создаём объект токенизатора, без ограничения числа токенов (num_words=None)\n",
    "tokenizer.fit_on_texts(texts) # обучаем токенизатор на текстах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число уникальных слов в корпусе: 1316.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('<OOV>', 1),\n",
       " (',', 2),\n",
       " ('.', 3),\n",
       " ('<start>', 4),\n",
       " ('<end>', 5),\n",
       " ('?', 6),\n",
       " ('не', 7),\n",
       " ('и', 8),\n",
       " ('что', 9),\n",
       " ('в', 10)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id = tokenizer.word_index # словарь соответствия слова его id_шнику (не ограничены MAX_FEATURES)\n",
    "id2word = tokenizer.index_word # словарь соответствия id_шника слову (не ограничены MAX_FEATURES)\n",
    "\n",
    "vocab_size = len(id2word) # число слов в корпусе\n",
    "docs_count = len(dataset) # число документов в корпусе\n",
    "\n",
    "print(f\"Число уникальных слов в корпусе: {vocab_size}.\") # включая специальные токены\n",
    "list(word2id.items())[:10] # первые 10 элементов словаря конвертации слова в токен (id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример токенизации документа: [4, 197, 1134, 60, 56, 256, 2, 78, 238, 38, 1135, 1136, 117, 215, 1137, 3, 113, 2, 16, 1138, 1139, 31, 5].\n"
     ]
    }
   ],
   "source": [
    "encoded_toxic = tokenizer.texts_to_sequences(dataset[\"Toxic comment\"]) # токенизируем документы\n",
    "encoded_polite = tokenizer.texts_to_sequences(dataset[\"Polite comment\"]) # токенизируем документы\n",
    "\n",
    "print(f\"Пример токенизации документа: {encoded_polite[0]}.\") # пример токенизации первого документа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример получившегося преобразования в токены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 — <start>\n",
      "197 — попробуйте\n",
      "1134 — почитать\n",
      "60 — посты\n",
      "56 — этого\n",
      "256 — автора\n",
      "2 — ,\n",
      "78 — может\n",
      "238 — быть\n",
      "38 — вам\n",
      "1135 — удастся\n",
      "1136 — найти\n",
      "117 — там\n",
      "215 — что-то\n",
      "1137 — полезное\n",
      "3 — .\n",
      "113 — надеюсь\n",
      "2 — ,\n",
      "16 — я\n",
      "1138 — смог\n",
      "1139 — помочь\n",
      "31 — )\n",
      "5 — <end>\n"
     ]
    }
   ],
   "source": [
    "for token in encoded_polite[0]: # идём по токенам примера 0\n",
    "    print(f\"{token} — {id2word[token]}\") # выводим токен (id) и соответствующее ему слово"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведение последовательностей токенов к одной длине (размерности)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная длина документа в токенах: 39.\n"
     ]
    }
   ],
   "source": [
    "lengths = [] # список под длины документов в токенах\n",
    "for doc in encoded_toxic + encoded_polite: # идём по токенизированным документам\n",
    "    lengths.append(len(doc)) # добавляем число токенов в документе в список\n",
    "\n",
    "print(f\"Максимальная длина документа в токенах: {max(lengths)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8)) # задание размера фигуры\n",
    "plt.hist(lengths, bins=20) # построение столбчатой диаграммы по данным\n",
    "plt.title(\"Распределение длин документов в токенах\") # название фигуры\n",
    "plt.xlabel(\"Длина документа\") # подпись по оси x\n",
    "plt.ylabel(\"Количество записей\") # подпись по оси y\n",
    "plt.show() # показ фигуры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Финальная размерность токенизированных документов: сэмплов — 199, токенов — 39.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   4,  197, 1134, ...,    0,    0,    0],\n",
       "       [   4,  198,    2, ...,    0,    0,    0],\n",
       "       [   4,  216,    2, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   4,  844, 1314, ...,    0,    0,    0],\n",
       "       [   4,   23,  848, ...,    0,    0,    0],\n",
       "       [   4,   27,    8, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_toxic = pad_sequences(encoded_toxic, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\", value=0) # приводим вектора токенов к единой размерности MAX_LEN с помощью padding_а и truncating_а (заполняем значением value)\n",
    "padded_polite = pad_sequences(encoded_polite, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\", value=0) # приводим вектора токенов к единой размерности MAX_LEN с помощью padding_а и truncating_а (заполняем значением value)\n",
    "\n",
    "print(f\"Финальная размерность токенизированных документов: сэмплов — {padded_polite.shape[0]}, токенов — {padded_polite.shape[1]}.\")\n",
    "padded_polite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word[0] = \"<pad>\" # добавление токена пропуска (<pad>) под индексом 0\n",
    "word2id[\"<pad>\"] = 0 # добавление токена пропуска (<pad>) под индексом 0\n",
    "vocab_size += 1 # увеличение размера словаря под токен паддинга (идёт под индексом 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = np.zeros(shape=(docs_count, MAX_LEN, vocab_size), dtype=DTYPE) # трёхмерный массив размерности (число документов, число токенов в документе, размер словаря) — таргеты (вероятности слова-токена word_id, что является t-ым токеном в d-м документе)\n",
    "for d, doc_tokenized in enumerate(padded_polite): # идём по документам в корпусе\n",
    "    for t, word_id in enumerate(doc_tokenized[1:]): # идём по токенам в документе (пропуская первый, <start>, так как он и так будет предоставлен)\n",
    "        if word_id > 0: # если токен не нулевой (паддинга)\n",
    "            target_data[d][t][word_id] = 1 # ставим ему вероятность = 1 (у всех остальных будут нулю на размерности, отвечающей за vocab_size)\n",
    "            # у всех токенов, что имеют значение паддинга, вероятности будут равные нулю (чтобы в них вообще ничего не предсказывалось)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data # вероятности слов на каждой позиции токена в документах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример разницы входа у декодера и ожидаемого выхода (argmax по вероятностям слов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   4,  197, 1134,   60,   56,  256,    2,   78,  238,   38, 1135,\n",
       "       1136,  117,  215, 1137,    3,  113,    2,   16, 1138, 1139,   31,\n",
       "          5,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_polite[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 197, 1134,   60,   56,  256,    2,   78,  238,   38, 1135, 1136,\n",
       "        117,  215, 1137,    3,  113,    2,   16, 1138, 1139,   31,    5,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(target_data[0], axis=1) # пример таргетов (axis=1 - по столбцам, то есть вероятностям слов на позиции токена t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Эмбеддинги"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для получения векторов-эмбеддингов воспользуемся [***Navec***](https://github.com/natasha/navec?tab=readme-ov-file), так как он компактный (легко умещается в память оперативную/физическую), хоть и имеет огромный словарь, и заточен под работу с русским языком. Словарь Navec содержит 500000 слов, представленных в виде векторов размерности 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "navec = Navec.load(f\"{EMBEDDING_DIR}navec_hudlit_v1_12B_500K_300d_100q.tar\") # загружаем вектора\n",
    "# navec_hudlit_v1_12B_500K_300d_100q.tar\n",
    "#                  |    |    |    |\n",
    "#                  |    |    |     ---- 100 dimentions after quantization\n",
    "#                  |    |     --------- original vectors have 300 dimentions\n",
    "#                  |     -------------- vocab size is 500 000 words + 2 for <unk>, <pad>\n",
    "#                   ------------------- dataset of 12 billion tokens was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.22543699, -0.39721358,  0.6805563 ,  0.21706595, -0.19716908,\n",
       "       -0.20722607, -0.07350219,  0.13129961, -0.17141329,  0.09088685,\n",
       "        0.21599719, -0.09282316,  0.00766279, -0.11043157, -0.07346303,\n",
       "        0.42286018, -0.26629096,  0.31371886, -0.08937341,  0.09485467,\n",
       "       -0.04480258, -0.44643393, -0.3061798 , -0.2882515 ,  0.5377174 ,\n",
       "        0.36234093,  0.0030303 ,  0.23453966, -0.28672412, -0.20668298,\n",
       "       -0.19193137,  0.04902396,  0.8125157 ,  0.5318507 , -0.6188356 ,\n",
       "       -0.04572238, -0.02173791, -0.66719943, -0.7230108 , -0.2762196 ,\n",
       "       -0.23562106,  0.5413357 , -0.05294172,  0.6201654 , -0.8374897 ,\n",
       "       -0.36382714,  0.4649254 , -0.13510832,  0.09727751, -0.10602053,\n",
       "        0.37899598, -0.36541265, -0.20060915,  0.10681065, -0.5519943 ,\n",
       "       -0.13753682, -0.01502502,  0.09474958, -0.05980838, -0.02857767,\n",
       "       -0.55855787, -0.04823827, -0.3578416 ,  0.88438463,  0.32023084,\n",
       "       -0.25467572,  0.22748815, -0.6873215 , -0.04857488, -0.7444249 ,\n",
       "       -0.41156083,  0.19128552,  0.07123397, -0.14737812, -0.39385885,\n",
       "       -0.24628565,  0.5453377 , -0.05320076,  0.06201499, -0.04103868,\n",
       "       -0.2932616 ,  0.3779095 , -0.31397003, -0.04615191, -0.43017006,\n",
       "       -0.00623761,  0.61113805,  0.2079509 , -0.05063467,  0.09398386,\n",
       "       -0.41160762,  0.09362367, -0.8432128 , -0.10191941,  0.01678637,\n",
       "        0.6130639 , -0.50620526,  0.06421215,  0.15180896, -1.001532  ,\n",
       "       -0.29364854, -0.1847418 ,  0.05156467, -0.23999164,  0.49402934,\n",
       "        0.34105918, -0.8930306 , -0.09359165,  0.5060184 ,  0.56454605,\n",
       "       -0.21829388,  0.05214137, -0.5776496 ,  0.13659137, -0.3143733 ,\n",
       "        0.12403905,  0.11754724,  0.09411987,  0.27510226, -0.05934107,\n",
       "       -0.39489806, -0.2788272 , -0.03585588,  0.39080086,  0.01645428,\n",
       "        0.00155893, -0.6858619 ,  0.03199653, -0.23169942, -0.57183355,\n",
       "        0.7449328 , -0.2478331 , -0.0656902 , -0.23359276, -0.15860626,\n",
       "        0.46892813,  0.25094634, -0.0038072 ,  0.8120501 , -0.3921491 ,\n",
       "        0.53953594,  0.0864343 ,  0.16530593, -0.34294814, -0.660825  ,\n",
       "        0.17502032,  0.1601436 ,  0.12880398,  0.2447404 , -0.1398195 ,\n",
       "        0.3940808 , -0.20316295,  0.40920585,  0.30853412,  0.24878557,\n",
       "       -0.08787356, -0.00201242, -0.0976093 ,  0.24608812, -0.20107856,\n",
       "       -0.08510465, -0.22498815, -0.24412297,  0.11659407, -0.23810975,\n",
       "        0.7927576 , -0.19332255,  0.35179833,  0.1266067 , -0.22534452,\n",
       "        0.22342923,  0.52875555, -0.13713977,  0.5322976 , -0.01586652,\n",
       "       -0.36773518,  0.18660183, -0.15345146, -0.6563604 ,  0.03934827,\n",
       "       -0.2537932 ,  0.5915523 ,  0.17447926,  0.08440425, -0.14555511,\n",
       "        0.8462292 ,  0.02306626, -0.50092953,  0.02497473,  0.09709087,\n",
       "        0.42852387, -0.12507445, -0.43765643, -0.04486881, -0.9197812 ,\n",
       "        0.15333776,  0.21755728,  0.16034487,  0.10947693,  0.26935494,\n",
       "        0.08937906, -0.32551923,  0.30181772,  0.03085733,  0.32175773,\n",
       "        0.58648676, -0.4552861 , -0.09058901, -0.07721699,  0.13540809,\n",
       "       -0.00645914, -0.24767125, -0.17353976, -0.32662928,  0.55255526,\n",
       "       -0.31210357,  0.71981466, -0.35557505, -0.2027955 ,  0.5551026 ,\n",
       "       -0.30438095, -0.41725138, -0.4683033 ,  0.03520601,  0.67806554,\n",
       "       -0.02468547,  0.33984688,  0.43193454, -0.27096793, -0.02520603,\n",
       "        0.286634  , -0.02133529, -0.55753946,  0.2741532 ,  0.21432668,\n",
       "       -0.4251435 ,  0.3402687 ,  0.3789248 ,  0.38285363, -0.01478797,\n",
       "        0.4644731 ,  0.21247226, -0.6237922 , -0.14217526, -0.36516917,\n",
       "        0.14149092, -0.15003966,  0.07534812, -0.26868176,  0.23520207,\n",
       "       -0.54361004, -0.9098788 , -0.3157734 ,  0.18669239, -0.0962809 ,\n",
       "       -0.37809882,  0.4742351 ,  0.13234845, -0.50550336,  0.17703918,\n",
       "       -0.44975471,  0.19239506,  0.30779085,  0.24575497,  0.5954058 ,\n",
       "        0.45039576, -0.16555037,  0.11469514, -0.0700791 ,  0.00519014,\n",
       "        0.64192   , -0.07611681, -0.04211494, -0.04530421, -0.69490165,\n",
       "       -0.5775567 , -0.34478965, -0.05541408,  0.5040086 ,  0.14443237,\n",
       "       -0.49850866,  0.23184095,  0.10807174, -0.06104805,  0.24632384,\n",
       "        0.4157553 , -0.3786785 , -0.18116818,  0.5042701 ,  0.6235093 ,\n",
       "        0.28725666, -0.41006738, -0.27313936, -0.1506457 , -0.24990621,\n",
       "       -0.3762372 ,  0.15003653, -0.05707216,  0.10502052,  0.30300924],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navec.get(\"россия\") # пример работы Navec (возвращает np.array типа float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполняем матрицу эмбеддингов векторами, соответствующими словам (или нулями, если слова нет в словаре Navec, они позже будут дообучены в модели)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропущенно 170 слов из 1317.\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM)) # создаём матрицу из нулей под эмбеддинги слов (+1 — для вектора паддинга, что будет идти под индексом 0)\n",
    "\n",
    "skipped_words = [] # список под слова без вектора\n",
    "for i in range(1, vocab_size): # идём по числу слов (токенов), начиная с 1, так как 0 под padding и до vocab_size не включительно (чтобы уместить все слова)\n",
    "    word = id2word[i] # слово, что идёт под номером i в токенизаторе\n",
    "    if navec.get(word) is not None: # если у рассматриваемого слова есть вектор в Navec (иначе вернёт None)\n",
    "        embedding_matrix[i] = navec.get(word) # записываем i-ый вектор в матрицу эмбеддингов\n",
    "    else: # если слова нет в Navec\n",
    "        skipped_words.append(word) # добавляем слово в список пропущенных\n",
    "\n",
    "print(f\"Пропущенно {len(skipped_words)} слов из {vocab_size}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа с моделью"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![seq2seq model](images/seq2seq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основная структура модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">395,100</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">395,100</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">570,368</span> │ encoder_embeddin… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">570,368</span> │ decoder_embeddin… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ word_probs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1317</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">338,469</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │    \u001b[38;5;34m395,100\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │    \u001b[38;5;34m395,100\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m570,368\u001b[0m │ encoder_embeddin… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m570,368\u001b[0m │ decoder_embeddin… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ word_probs (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m1317\u001b[0m)  │    \u001b[38;5;34m338,469\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,269,405</span> (8.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,269,405\u001b[0m (8.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,269,405</span> (8.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,269,405\u001b[0m (8.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# энкодер (на вход идут токсичные сообщения)\n",
    "encoder_input = Input(shape=(MAX_LEN,), dtype=DTYPE, name='encoder_input') # входной слой энкодера, получает вектор размера (BATCH_SIZE, число слов или токенов в входных данных)\n",
    "encoder_embedding = Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, name='encoder_embedding')(encoder_input) # слой эмбеддинга (на вход — encoder_input размера словаря input_dim, выход размерности (BATCH_SIZE, число токенов в документе, размерность вектора-эмбеддинга))\n",
    "encoder_output, encoder_hidden_state, encoder_context = LSTM(units=ENCODING_DIM, return_state=True, name='encoder_lstm')(encoder_embedding) # слой LSTM, return_state — возвращающий помимо выхода слоя, также свой hidden_state и вектор context_а\n",
    "encoder_state = [encoder_hidden_state, encoder_context] # запоминаем hidden_state и вектор context_а энкодера (пойдут как начальное состояние декодера)\n",
    "# РАБОТА С ВЫХОДОМ ЭНКОДЕРА БОЛЬШЕ НЕ ВЕДЁТСЯ, А ТОЛЬКО С ЕГО СОСТОЯНИЕМ ПРИ ВЫХОДЕ\n",
    "\n",
    "\n",
    "# декодер (на вход идут нетоксичные сообщения)\n",
    "#=================================== v1 ========================================\n",
    "# decoder_input = Input(shape=(MAX_LEN,), dtype=DTYPE, name='decoder_input') # входной слой декодера, получает вектор размера (BATCH_SIZE, число слов или токенов в выходных данных)\n",
    "# decoder_embedding_layer = Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, name='decoder_embedding') # слой эмбеддинга (на вход — decoder_input размера словаря input_dim, выход размерности (BATCH_SIZE, число токенов в документе, размерность вектора-эмбеддинга))\n",
    "# decoder_embedding = decoder_embedding_layer(decoder_input) # вызов слоя эмбеддинга\n",
    "# decoder_lstm_layer = LSTM(units=ENCODING_DIM, return_sequences=True, return_state=True, name='decoder_lstm') # слой LSTM, return_state — возвращающий помимо выхода слоя, также свой hidden_state и вектор context_а; return_sequences — возвращать лишь последний выход или выходы для всй входной последовательности (True - чтобы предсказывать целую последовательность, иначе было бы лишь одно число)\n",
    "# decoder_lstm, _, _ = decoder_lstm_layer(decoder_embedding, initial_state=encoder_state) # вызываем слой LSTM с передачей внутреннего состояния из энкодера\n",
    "# decoder_dense_layer = Dense(units=vocab_size, activation=\"softmax\", name='word_probs') # линейный слой с \"softmax\" для получения вероятностей слов (units=vocab_size) на позиции токена t, а так как LSTM возвращает последовательность (return_sequences=True) - выходом будет трёхмерная матрица (BATCH_SIZE, число токенов в документе, размер словаря)\n",
    "# decoder_output = decoder_dense_layer(decoder_lstm) # вызываем линейный слой\n",
    "#----------------------------------- v2 ----------------------------------------\n",
    "decoder_input = Input(shape=(MAX_LEN,), dtype=DTYPE, name='decoder_input') # входной слой декодера, получает вектор размера (BATCH_SIZE, число слов или токенов в выходных данных)\n",
    "decoder_embedding = Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, name='decoder_embedding')(decoder_input) # слой эмбеддинга (на вход — decoder_input размера словаря input_dim, выход размерности (BATCH_SIZE, число токенов в документе, размерность вектора-эмбеддинга))\n",
    "decoder_lstm, _, _ = LSTM(units=ENCODING_DIM, return_sequences=True, return_state=True, name='decoder_lstm')(decoder_embedding, initial_state=encoder_state) # слой LSTM, return_state — возвращающий помимо выхода слоя, также свой hidden_state и вектор context_а; return_sequences — возвращать лишь последний выход или выходы для всй входной последовательности (True - чтобы предсказывать целую последовательность, иначе было бы лишь одно число)\n",
    "decoder_output = Dense(units=vocab_size, activation=\"softmax\", name='word_probs')(decoder_lstm) # линейный слой с \"softmax\" для получения вероятностей слов (units=vocab_size) на позиции токена t, а так как LSTM возвращает последовательность (return_sequences=True) - выходом будет трёхмерная матрица (BATCH_SIZE, число токенов в документе, размер словаря)\n",
    "#===============================================================================\n",
    "\n",
    "\n",
    "# общая модель\n",
    "model = Model(inputs=[encoder_input, decoder_input], outputs=decoder_output) # финальное объединение в одну модель\n",
    "\n",
    "model.summary() # вывод данных о модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Устанавливаем специфичные веса и параметры обучения для слоя эмбеддинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<InputLayer name=encoder_input, built=True>,\n",
       " <InputLayer name=decoder_input, built=True>,\n",
       " <Embedding name=encoder_embedding, built=True>,\n",
       " <Embedding name=decoder_embedding, built=True>,\n",
       " <LSTM name=encoder_lstm, built=True>,\n",
       " <LSTM name=decoder_lstm, built=True>,\n",
       " <Dense name=word_probs, built=True>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2].set_weights([embedding_matrix]) # устанавливаем вектора эмбеддингов\n",
    "# model.layers[2].trainable = False # ставим флаг, что слой не будет обучаться\n",
    "model.layers[3].set_weights([embedding_matrix]) # устанавливаем вектора эмбеддингов\n",
    "# model.layers[3].trainable = False # ставим флаг, что слой не будет обучаться"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_early_stopping():\n",
    "    \"\"\"\n",
    "    This function should return an EarlyStopping callback that stops learning when the\n",
    "    validation (testing) accuracy has not improved over the last N epochs.\n",
    "    \"\"\"\n",
    "    early_stopping = EarlyStopping(monitor=\"loss\", mode=\"min\", patience=EPOCHS_PATIENCE) # callback ранней остановки обучения\n",
    "    # monitor — по какой метрике судить, нужно ли прекращать обучение, например - val_loss\n",
    "    # mode — метрика должна увеличиваться (max) или уменьшаться (min)\n",
    "    # patience — сколько должно пройти эпох без улучшения отслеживаемой метрики чтобы прекратить обучение\n",
    "    return early_stopping\n",
    "\n",
    "\n",
    "def get_checkpoint_best_only():\n",
    "    \"\"\"\n",
    "    This function should return a ModelCheckpoint object that:\n",
    "    - stores only those weights of the neural network that generate the highest accuracy during testing\n",
    "    - saves to the 'checkpoints_best_only' directory inside the current working directory\n",
    "    - generates a file named '{MODELS_DIR}best_model.keras'\n",
    "    \"\"\"\n",
    "    checkpoint_best = ModelCheckpoint(filepath=f\"{MODELS_DIR}best_model.keras\", save_best_only=True, save_weights_only=False, monitor=\"loss\", mode=\"min\") # callback сохранения чекпоинтов модели\n",
    "    # filepath — путь до файла, куда сохранять (можно с указанием эпохи...)\n",
    "    # save_best_only — сохранять только если результат (отслеживаемая метрика) улучшилась\n",
    "    # save_weights_only — сохранять ли только веса\n",
    "    # monitor — по какой метрике судить, стала ли модель лучше/хуже\n",
    "    # mode — метрика должна увеличиваться (max) или уменьшаться (min)\n",
    "    return checkpoint_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сборка модели с обучением"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Переобучение для моделей генерации и перевода (детоксикации) текста на самом деле положительно сказывается на её ответах.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=None) # компилирование модели с указанием оптимизатора, функции потерь и дополнительных метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_checkpoint = get_checkpoint_best_only() # callback сохранения чекпоинтов\n",
    "callback_stopping = get_early_stopping() # callback ранней остановки обучения\n",
    "\n",
    "callbacks = [callback_checkpoint, callback_stopping] # список callback_ов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 174ms/step - loss: 2.3094\n",
      "Epoch 2/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 151ms/step - loss: 2.0379\n",
      "Epoch 3/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.9028\n",
      "Epoch 4/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 1.9417\n",
      "Epoch 5/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 172ms/step - loss: 1.7245\n",
      "Epoch 6/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 166ms/step - loss: 1.9318\n",
      "Epoch 7/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 171ms/step - loss: 1.8552\n",
      "Epoch 8/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 1.8030\n",
      "Epoch 9/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 161ms/step - loss: 1.8428\n",
      "Epoch 10/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 169ms/step - loss: 1.7902\n",
      "Epoch 11/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 151ms/step - loss: 1.8303\n",
      "Epoch 12/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 168ms/step - loss: 1.7453\n",
      "Epoch 13/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 1.8324\n",
      "Epoch 14/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 168ms/step - loss: 1.7572\n",
      "Epoch 15/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - loss: 1.7489\n",
      "Epoch 16/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - loss: 1.7694\n",
      "Epoch 17/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 1.7747\n",
      "Epoch 18/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 1.7324\n",
      "Epoch 19/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 1.6608\n",
      "Epoch 20/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - loss: 1.7613\n",
      "Epoch 21/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 179ms/step - loss: 1.6409\n",
      "Epoch 22/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 161ms/step - loss: 1.6832\n",
      "Epoch 23/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 179ms/step - loss: 1.7966\n",
      "Epoch 24/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 166ms/step - loss: 1.5758\n",
      "Epoch 25/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - loss: 1.7211\n",
      "Epoch 26/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - loss: 1.6113\n",
      "Epoch 27/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 151ms/step - loss: 1.8136\n",
      "Epoch 28/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 1.6412\n",
      "Epoch 29/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - loss: 1.7139\n",
      "Epoch 30/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - loss: 1.6374\n",
      "Epoch 31/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 167ms/step - loss: 1.6659\n",
      "Epoch 32/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 1.6435\n",
      "Epoch 33/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 172ms/step - loss: 1.6785\n",
      "Epoch 34/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - loss: 1.5960\n",
      "Epoch 35/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - loss: 1.6256\n",
      "Epoch 36/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 187ms/step - loss: 1.6370\n",
      "Epoch 37/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - loss: 1.5086\n",
      "Epoch 38/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - loss: 1.6887\n",
      "Epoch 39/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - loss: 1.6121\n",
      "Epoch 40/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 1.4982\n",
      "Epoch 41/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - loss: 1.5406\n",
      "Epoch 42/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 343ms/step - loss: 1.5443\n",
      "Epoch 43/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 160ms/step - loss: 1.5608\n",
      "Epoch 44/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - loss: 1.5177\n",
      "Epoch 45/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 154ms/step - loss: 1.5702\n",
      "Epoch 46/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - loss: 1.4936\n",
      "Epoch 47/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 1.4820\n",
      "Epoch 48/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 1.4619\n",
      "Epoch 49/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 1.6089\n",
      "Epoch 50/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 163ms/step - loss: 1.5082\n",
      "Epoch 51/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - loss: 1.6116\n",
      "Epoch 52/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 1.5982\n",
      "Epoch 53/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 1.5150\n",
      "Epoch 54/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - loss: 1.4576\n",
      "Epoch 55/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 1.4625\n",
      "Epoch 56/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - loss: 1.5029\n",
      "Epoch 57/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 1.4826\n",
      "Epoch 58/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 1.4622\n",
      "Epoch 59/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - loss: 1.5665\n",
      "Epoch 60/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 172ms/step - loss: 1.3936\n",
      "Epoch 61/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 155ms/step - loss: 1.4570\n",
      "Epoch 62/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 163ms/step - loss: 1.4746\n",
      "Epoch 63/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 152ms/step - loss: 1.4397\n",
      "Epoch 64/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - loss: 1.4188\n",
      "Epoch 65/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - loss: 1.4987\n",
      "Epoch 66/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 1.3588\n",
      "Epoch 67/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - loss: 1.4125\n",
      "Epoch 68/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 152ms/step - loss: 1.4019\n",
      "Epoch 69/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 308ms/step - loss: 1.4221\n",
      "Epoch 70/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - loss: 1.3330\n",
      "Epoch 71/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 164ms/step - loss: 1.4377\n",
      "Epoch 72/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 170ms/step - loss: 1.3434\n",
      "Epoch 73/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 166ms/step - loss: 1.3616\n",
      "Epoch 74/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 179ms/step - loss: 1.3049\n",
      "Epoch 75/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 160ms/step - loss: 1.3387\n",
      "Epoch 76/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - loss: 1.3025\n",
      "Epoch 77/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 191ms/step - loss: 1.4622\n",
      "Epoch 78/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 1.3364\n",
      "Epoch 79/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 1.2868\n",
      "Epoch 80/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - loss: 1.3000\n",
      "Epoch 81/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 1.4359\n",
      "Epoch 82/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - loss: 1.3442\n",
      "Epoch 83/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - loss: 1.2862\n",
      "Epoch 84/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - loss: 1.3233\n",
      "Epoch 85/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 174ms/step - loss: 1.3090\n",
      "Epoch 86/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 1.3437\n",
      "Epoch 87/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 154ms/step - loss: 1.2916\n",
      "Epoch 88/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 1.4035\n",
      "Epoch 89/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - loss: 1.1971\n",
      "Epoch 90/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 160ms/step - loss: 1.2308\n",
      "Epoch 91/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - loss: 1.2278\n",
      "Epoch 92/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 200ms/step - loss: 1.3339\n",
      "Epoch 93/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 309ms/step - loss: 1.2870\n",
      "Epoch 94/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 1.1431\n",
      "Epoch 95/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - loss: 1.1428\n",
      "Epoch 96/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 1.1979\n",
      "Epoch 97/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 1.1938\n",
      "Epoch 98/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - loss: 1.1925\n",
      "Epoch 99/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - loss: 1.2202\n",
      "Epoch 100/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 153ms/step - loss: 1.1564\n",
      "Epoch 101/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 153ms/step - loss: 1.1288\n",
      "Epoch 102/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 153ms/step - loss: 1.1691\n",
      "Epoch 103/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 1.0961\n",
      "Epoch 104/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 154ms/step - loss: 1.1223\n",
      "Epoch 105/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 152ms/step - loss: 1.1939\n",
      "Epoch 106/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - loss: 1.1269\n",
      "Epoch 107/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 1.1531\n",
      "Epoch 108/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - loss: 1.0881\n",
      "Epoch 109/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 1.0707\n",
      "Epoch 110/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 1.0258\n",
      "Epoch 111/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 1.1021\n",
      "Epoch 112/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - loss: 1.1683\n",
      "Epoch 113/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 1.1267\n",
      "Epoch 114/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 1.0522\n",
      "Epoch 115/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 1.1284\n",
      "Epoch 116/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 164ms/step - loss: 1.0864\n",
      "Epoch 117/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 1.1538\n",
      "Epoch 118/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 252ms/step - loss: 0.9968\n",
      "Epoch 119/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 209ms/step - loss: 0.9754\n",
      "Epoch 120/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 1.0219\n",
      "Epoch 121/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 166ms/step - loss: 0.9473\n",
      "Epoch 122/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 165ms/step - loss: 1.0159\n",
      "Epoch 123/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - loss: 1.0873\n",
      "Epoch 124/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 1.0207\n",
      "Epoch 125/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - loss: 1.0308\n",
      "Epoch 126/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.9691\n",
      "Epoch 127/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - loss: 0.9876\n",
      "Epoch 128/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - loss: 1.0496\n",
      "Epoch 129/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.9972\n",
      "Epoch 130/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 154ms/step - loss: 0.9275\n",
      "Epoch 131/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.0267\n",
      "Epoch 132/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 0.8487\n",
      "Epoch 133/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.8905\n",
      "Epoch 134/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 0.9458\n",
      "Epoch 135/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 0.8418\n",
      "Epoch 136/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 161ms/step - loss: 0.8596\n",
      "Epoch 137/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 151ms/step - loss: 0.9244\n",
      "Epoch 138/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.8484\n",
      "Epoch 139/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - loss: 0.8280\n",
      "Epoch 140/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.9670\n",
      "Epoch 141/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 0.8551\n",
      "Epoch 142/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 186ms/step - loss: 0.8295\n",
      "Epoch 143/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 313ms/step - loss: 0.8599\n",
      "Epoch 144/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - loss: 0.8203\n",
      "Epoch 145/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 0.8323\n",
      "Epoch 146/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - loss: 0.8188\n",
      "Epoch 147/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.8288\n",
      "Epoch 148/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.8147\n",
      "Epoch 149/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 0.8272\n",
      "Epoch 150/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.7741\n",
      "Epoch 151/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 187ms/step - loss: 0.8389\n",
      "Epoch 152/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - loss: 0.7565\n",
      "Epoch 153/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 153ms/step - loss: 0.7378\n",
      "Epoch 154/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 161ms/step - loss: 0.7809\n",
      "Epoch 155/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 161ms/step - loss: 0.7983\n",
      "Epoch 156/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.7480\n",
      "Epoch 157/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 166ms/step - loss: 0.7808\n",
      "Epoch 158/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.7746\n",
      "Epoch 159/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 154ms/step - loss: 0.7469\n",
      "Epoch 160/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - loss: 0.7975\n",
      "Epoch 161/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - loss: 0.7157\n",
      "Epoch 162/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 0.7118\n",
      "Epoch 163/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - loss: 0.8105\n",
      "Epoch 164/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 179ms/step - loss: 0.7362\n",
      "Epoch 165/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 168ms/step - loss: 0.6867\n",
      "Epoch 166/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - loss: 0.7002\n",
      "Epoch 167/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.6959\n",
      "Epoch 168/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.7116\n",
      "Epoch 169/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 0.7241\n",
      "Epoch 170/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 307ms/step - loss: 0.7587\n",
      "Epoch 171/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.7131\n",
      "Epoch 172/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - loss: 0.7000\n",
      "Epoch 173/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.6675\n",
      "Epoch 174/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.7412\n",
      "Epoch 175/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 155ms/step - loss: 0.6314\n",
      "Epoch 176/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 169ms/step - loss: 0.6338\n",
      "Epoch 177/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 0.6951\n",
      "Epoch 178/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 164ms/step - loss: 0.6991\n",
      "Epoch 179/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - loss: 0.6955\n",
      "Epoch 180/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 172ms/step - loss: 0.6735\n",
      "Epoch 181/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 168ms/step - loss: 0.6074\n",
      "Epoch 182/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 0.6656\n",
      "Epoch 183/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 0.6363\n",
      "Epoch 184/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - loss: 0.6206\n",
      "Epoch 185/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 0.6202\n",
      "Epoch 186/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - loss: 0.5893\n",
      "Epoch 187/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - loss: 0.5838\n",
      "Epoch 188/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 199ms/step - loss: 0.6406\n",
      "Epoch 189/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 250ms/step - loss: 0.6018\n",
      "Epoch 190/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 0.6278\n",
      "Epoch 191/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 0.6268\n",
      "Epoch 192/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 0.6300\n",
      "Epoch 193/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - loss: 0.5539\n",
      "Epoch 194/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - loss: 0.6086\n",
      "Epoch 195/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - loss: 0.5847\n",
      "Epoch 196/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 0.6224\n",
      "Epoch 197/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 0.5902\n",
      "Epoch 198/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - loss: 0.5245\n",
      "Epoch 199/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - loss: 0.5518\n",
      "Epoch 200/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 0.4968\n",
      "Epoch 201/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - loss: 0.5486\n",
      "Epoch 202/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.6363\n",
      "Epoch 203/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - loss: 0.5103\n",
      "Epoch 204/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 161ms/step - loss: 0.6050\n",
      "Epoch 205/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 161ms/step - loss: 0.4969\n",
      "Epoch 206/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - loss: 0.5357\n",
      "Epoch 207/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 160ms/step - loss: 0.4917\n",
      "Epoch 208/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 161ms/step - loss: 0.5825\n",
      "Epoch 209/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - loss: 0.5390\n",
      "Epoch 210/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 245ms/step - loss: 0.4799\n",
      "Epoch 211/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 205ms/step - loss: 0.5332\n",
      "Epoch 212/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - loss: 0.4758\n",
      "Epoch 213/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 153ms/step - loss: 0.5104\n",
      "Epoch 214/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 0.4987\n",
      "Epoch 215/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 0.5107\n",
      "Epoch 216/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 161ms/step - loss: 0.5131\n",
      "Epoch 217/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 166ms/step - loss: 0.5397\n",
      "Epoch 218/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 167ms/step - loss: 0.4597\n",
      "Epoch 219/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - loss: 0.4861\n",
      "Epoch 220/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 0.4581\n",
      "Epoch 221/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - loss: 0.5199\n",
      "Epoch 222/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 151ms/step - loss: 0.5046\n",
      "Epoch 223/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - loss: 0.4608\n",
      "Epoch 224/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.5111\n",
      "Epoch 225/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 152ms/step - loss: 0.5027\n",
      "Epoch 226/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 0.4714\n",
      "Epoch 227/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - loss: 0.4638\n",
      "Epoch 228/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 0.4991\n",
      "Epoch 229/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - loss: 0.5209\n",
      "Epoch 230/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 151ms/step - loss: 0.4930\n",
      "Epoch 231/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 165ms/step - loss: 0.4447\n",
      "Epoch 232/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 0.5012\n",
      "Epoch 233/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 0.4950\n",
      "Epoch 234/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 0.4823\n",
      "Epoch 235/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.4704\n",
      "Epoch 236/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 160ms/step - loss: 0.4655\n",
      "Epoch 237/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 287ms/step - loss: 0.4445\n",
      "Epoch 238/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - loss: 0.4352\n",
      "Epoch 239/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - loss: 0.4345\n",
      "Epoch 240/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - loss: 0.4404\n",
      "Epoch 241/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 0.4042\n",
      "Epoch 242/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 155ms/step - loss: 0.4309\n",
      "Epoch 243/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 0.4246\n",
      "Epoch 244/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - loss: 0.3926\n",
      "Epoch 245/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 0.3878\n",
      "Epoch 246/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 0.3826\n",
      "Epoch 247/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - loss: 0.4487\n",
      "Epoch 248/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - loss: 0.3898\n",
      "Epoch 249/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - loss: 0.4080\n",
      "Epoch 250/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 0.4005\n",
      "Epoch 251/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - loss: 0.3881\n",
      "Epoch 252/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 173ms/step - loss: 0.3937\n",
      "Epoch 253/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.3902\n",
      "Epoch 254/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.3870\n",
      "Epoch 255/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 0.3751\n",
      "Epoch 256/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.4453\n",
      "Epoch 257/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 0.4112\n",
      "Epoch 258/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.3963\n",
      "Epoch 259/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 0.3928\n",
      "Epoch 260/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 0.4248\n",
      "Epoch 261/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 251ms/step - loss: 0.3488\n",
      "Epoch 262/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.3863\n",
      "Epoch 263/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.3500\n",
      "Epoch 264/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.3809\n",
      "Epoch 265/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.3839\n",
      "Epoch 266/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.3968\n",
      "Epoch 267/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 0.3612\n",
      "Epoch 268/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 0.3651\n",
      "Epoch 269/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.3277\n",
      "Epoch 270/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.3998\n",
      "Epoch 271/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.3728\n",
      "Epoch 272/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - loss: 0.3315\n",
      "Epoch 273/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.3222\n",
      "Epoch 274/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 0.3274\n",
      "Epoch 275/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 0.3516\n",
      "Epoch 276/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 0.3434\n",
      "Epoch 277/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.3548\n",
      "Epoch 278/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 0.3105\n",
      "Epoch 279/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - loss: 0.3844\n",
      "Epoch 280/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - loss: 0.3385\n",
      "Epoch 281/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 161ms/step - loss: 0.3134\n",
      "Epoch 282/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.3296\n",
      "Epoch 283/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 0.3524\n",
      "Epoch 284/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.3456\n",
      "Epoch 285/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 152ms/step - loss: 0.3490\n",
      "Epoch 286/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - loss: 0.3184\n",
      "Epoch 287/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.3046\n",
      "Epoch 288/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - loss: 0.2999\n",
      "Epoch 289/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.3272\n",
      "Epoch 290/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 0.3018\n",
      "Epoch 291/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.3530\n",
      "Epoch 292/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 304ms/step - loss: 0.3024\n",
      "Epoch 293/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - loss: 0.3213\n",
      "Epoch 294/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - loss: 0.2985\n",
      "Epoch 295/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.2875\n",
      "Epoch 296/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 0.3114\n",
      "Epoch 297/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 0.3356\n",
      "Epoch 298/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 173ms/step - loss: 0.3337\n",
      "Epoch 299/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 153ms/step - loss: 0.2922\n",
      "Epoch 300/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 206ms/step - loss: 0.2889\n",
      "Время, затраченное на обучение: 958.2534577846527 секунд.\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time() # замеряем время начала обучения\n",
    "\n",
    "history = model.fit(x=[padded_toxic, padded_polite], y=target_data, validation_data=None, validation_split=0, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks, verbose=1) # запускаем обучение модели (результатом которого будет история изменения метрик)\n",
    "# x — вход модели (а данном случае — двойной)\n",
    "# y — таргеты\n",
    "# epochs — число эпох обучения\n",
    "# batch_size — размер батчка\n",
    "# validation_data — тестовые данные (тестовый двойной вход и его таргеты)\n",
    "# validation_split — если validation_data=None, то validation_split определяет, какой процент данных будет использован для валидации (на нём не будет обучения), например 0.2\n",
    "# callbacks — список callback функций\n",
    "# verbose — на сколько подробно выводить информацию об обучении (1 - на каждой эпохе)\n",
    "\n",
    "print(f\"Время, затраченное на обучение: {time.time()  - time_start} секунд.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history # словарь с историей обучения\n",
    "print(history_dict.keys()) # ключи в словаре истории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8)) # задание размера графика\n",
    "epochs = range(1, len(history_dict['loss']) + 1) # число эпох обучения (сколько было сохранено значений loss)\n",
    "plt.plot(epochs, history_dict[\"loss\"], 'b', label='Training loss') # построение линейного графика ('b' — синего цвета)\n",
    "plt.title(\"Изменение значения loss функции в зависимости от эпохи обучения\") # название фигуры\n",
    "plt.xlabel('Эпоха') # подпись по оси OX\n",
    "plt.ylabel('loss') # подпись по оси OY\n",
    "plt.legend() # вывод подписей для графиков\n",
    "plt.show() # показ фигуры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{MODELS_DIR}final_model.keras\") # сохранение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем сохранённую модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<InputLayer name=encoder_input, built=True>,\n",
       " <InputLayer name=decoder_input, built=True>,\n",
       " <Embedding name=encoder_embedding, built=True>,\n",
       " <Embedding name=decoder_embedding, built=True>,\n",
       " <LSTM name=encoder_lstm, built=True>,\n",
       " <LSTM name=decoder_lstm, built=True>,\n",
       " <Dense name=word_probs, built=True>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(f\"{MODELS_DIR}best_model.keras\") # загружаем сохранённую модель\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы грузим модель извне, то нужно описать входы, выходы и промежуточный вектор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Энкодер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = model.input[0] # вход энкодера\n",
    "\n",
    "#=================================== v1 ========================================\n",
    "# encoder_output, *encoder_state = model.layers[4].output # выход энкодера (из LSTM), hidden_state и context сразу записываем в encoder_state\n",
    "#----------------------------------- v2 ----------------------------------------\n",
    "encoder_embedding = model.layers[2](encoder_input) # вызываем слой эмбеддинга энкодера\n",
    "encoder_output, *encoder_state = model.layers[4](encoder_embedding) # вызываем слой LSTM энкодера, hidden_state и context сразу записываем в encoder_state\n",
    "#===============================================================================\n",
    "\n",
    "encoder_model = Model(inputs=encoder_input, outputs=encoder_state) # модель энкодера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<InputLayer name=encoder_input, built=True>,\n",
       " <Embedding name=encoder_embedding, built=True>,\n",
       " <LSTM name=encoder_lstm, built=True>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model.layers # получили обратно все слои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Декодер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = model.input[1] # вход декодера\n",
    "\n",
    "decoder_hidden_state = Input(shape=(ENCODING_DIM,), name='decoder_hidden_state') # hidden_state декодера идёт сначала пустым\n",
    "decoder_context = Input(shape=(ENCODING_DIM,), name='decoder_context') # context вектор декодера идёт сначала пустым\n",
    "decoder_state_input = [decoder_hidden_state, decoder_context] # запоминаем hidden_state и вектор context_а декодера (пойдут как начальное состояние)\n",
    "\n",
    "# decoder_embedding = decoder_embedding_layer(decoder_input) # вызываем слой эмбеддинга декодера\n",
    "decoder_embedding = model.layers[3](decoder_input) # вызываем слой эмбеддинга декодера\n",
    "\n",
    "# decoder_lstm, *decoder_state = decoder_lstm_layer(decoder_embedding, initial_state=decoder_state_input) # вызываем слой LSTM декодера, hidden_state и context сразу записываем в encoder_state\n",
    "decoder_lstm, *decoder_state = model.layers[5](decoder_embedding, initial_state=decoder_state_input) # вызываем слой LSTM декодера, hidden_state и context сразу записываем в encoder_state\n",
    "\n",
    "# decodet_output = decoder_dense_layer(decoder_lstm) # вызываем линейный слой для получения вероятностей слов\n",
    "decodet_output = model.layers[6](decoder_lstm) # вызываем линейный слой для получения вероятностей слов\n",
    "\n",
    "decoder_model = Model(inputs=[decoder_input] + decoder_state_input, outputs=[decodet_output] + decoder_state) # модель декодера с нексолькими данными на вход (токены и state) и выход (вероятности слов на позициях и state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<InputLayer name=decoder_input, built=True>,\n",
       " <Embedding name=decoder_embedding, built=True>,\n",
       " <InputLayer name=decoder_hidden_state, built=True>,\n",
       " <InputLayer name=decoder_context, built=True>,\n",
       " <LSTM name=decoder_lstm, built=True>,\n",
       " <Dense name=word_probs, built=True>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_model.layers # получили обратно все слои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Детоксикация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# процедура декодирования последовательности\n",
    "def decode_sequence(input_seq) -> str:\n",
    "    \"\"\"\n",
    "    Функция для конвертированя вероятностей токенов на каждой позиции в слова.\\n\n",
    "    Parameters:\n",
    "        * input_seq: входная последовательность для энкодера (список токенов)\\n\n",
    "    Returns:\n",
    "        * str: декодированная строка\n",
    "    \"\"\"\n",
    "    state = encoder_model.predict(input_seq) # делаем предсказание по токенам при помощи энкодера и получаем на выходе его state\n",
    "\n",
    "    # создаём \"вектор\" таргетов, что пойдёт на вход декодеру, начинается с токена <start> (будет передаваться в модель, пока не сгенерируется токен окончания предсказания)\n",
    "    target_seq = np.zeros((1, 1)) # создадим пустой вектор, который будет содержать нашу предсказанную последовательнось, размерности (BATCH_SIZE=1, токены таргета)\n",
    "    target_seq[0, 0] = word2id[\"<start>\"] # первый символ target последовательности будет токен \"<start>\"\n",
    "\n",
    "    # проводим процедуру генерации токенов\n",
    "    stop_condition = False # ключ для выхода генерации перевода\n",
    "    decoded_sentence = \"\" # строка получившегося перевода\n",
    "    decoded_counter = 0 # счётчик числа декодированных токенов\n",
    "    while not stop_condition: # пока не выполнено условие прекращения генерации\n",
    "        # генерируем текущий токен на основе пока пустой target последовательности (в ней только токен <start>) и state из энкодера\n",
    "        # процес повторяется, шаг за шагом, в ходе итерауий модель генерируем последовальность токенов\n",
    "        output_tokens, *state = decoder_model.predict([target_seq] + state) # декодируем последовательность с учётом внутреннего состояния\n",
    "\n",
    "        pred_token = np.argmax(output_tokens[0, -1, :]) # определяем id самого вероятного токена (0 — так как BATCH_SIZE=1 при инференсе, -1 — токен на последней сгенерированной позиции, : — среди всех вероятности слов)        \n",
    "        pred_word = id2word[pred_token] # определяем слово на основе его id (токена)\n",
    "        target_seq[0, 0] = pred_token # обновляем target за счет нового токена для следующего шага (всегда будет состоять из последнего полученного токена, так как декодер ожидает на вход только один токен, помимо state)\n",
    "\n",
    "        if pred_word in [\"<end>\", \"<pad>\"] or decoded_counter >= MAX_LEN: # условие остановки — достижение максимальной длины (числа токенов), либо найдены токены <end> или <pad>\n",
    "            stop_condition = True # меняем флаг прекращения генерации токенов\n",
    "        else:\n",
    "            decoded_sentence += f\" {pred_word}\" # добавляем слово в конец полученной декодируемой строки с пробелом\n",
    "            decoded_counter += 1 # обновляем счётчик декодированных токенов в последовательности\n",
    "\n",
    "    decoded_sentence = re.sub(r'\\s+(?=(?:[,.?!:;…]))', r'', decoded_sentence) # удаляем пробелы перед знаками препинания\n",
    "    return decoded_sentence.strip() # возвращаем строку без пробелов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токсичный текст: Ну ты и дурак, не умеешь читать между строк?\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Обработанный текст: вы, дорогой, просто не умеете читать между строк.\n"
     ]
    }
   ],
   "source": [
    "text = \"Ну ты и дурак, не умеешь читать между строк?\" # приходящий текст\n",
    "print(f\"Токсичный текст: {text}\")\n",
    "\n",
    "sequence = word_tokenize(text) # разбиваем текст на слова (токены)\n",
    "text = \" \".join(sequence) # собираем последовательность слов обратно в строку, но теперь даже служебные символы разделены пробелами\n",
    "encoded_text = tokenizer.texts_to_sequences([text]) # токенизируем текст\n",
    "padded_text = pad_sequences(encoded_text, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\", value=0) # приводим вектора токенов к единой размерности MAX_LEN с помощью padding_а и truncating_а (заполняем значением value)\n",
    "\n",
    "decoded_sentence = decode_sequence(padded_text) # обрабатываем пришедший текст\n",
    "print(f\"Обработанный текст: {decoded_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 — ну\n",
      "11 — ты\n",
      "8 — и\n",
      "1131 — дурак\n",
      "2 — ,\n",
      "7 — не\n",
      "375 — умеешь\n",
      "157 — читать\n",
      "158 — между\n",
      "159 — строк\n",
      "6 — ?\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n",
      "0 — <pad>\n"
     ]
    }
   ],
   "source": [
    "for token in padded_text[0]: # идём по токенам\n",
    "    print(f\"{token} — {id2word[token]}\") # выводим токен (id) и соответствующее ему слово"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
