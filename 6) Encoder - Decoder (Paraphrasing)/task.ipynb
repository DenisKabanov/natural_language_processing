{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построить нейронную сеть по архитектуре ***Encoder – Decoder***, что должна переводить токсичные комменты в нетоксичные (***Paraphrasing***/***Translation***).\n",
    "* В архитектуре сети обязательно использование слоя эмбеддинга и LSTM (реализация с помощью ***Keras***)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Настройки/Импорты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Версии важных модулей:\n",
    "* pandas==2.1.1\n",
    "* numpy==1.26.2\n",
    "* keras==3.3.3\n",
    "* tensorflow==2.16.1 (no GPU)\n",
    "* matplotlib==3.6.2\n",
    "* navec==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # для работы с массивами\n",
    "import pandas as pd # для удобной работы с датасетом\n",
    "\n",
    "import re # для регулярных выражений\n",
    "\n",
    "from nltk.tokenize import word_tokenize # для токенизации строк\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # токенизатор текста (на версии keras 2.15.0 можно было не тягать из tensorflow)\n",
    "from keras.utils import pad_sequences # для приведения векторов токенов к единой размерности\n",
    "from navec import Navec # для русскоязычных эмбеддингов\n",
    "\n",
    "from keras.layers import Input, Dense, Embedding, LSTM # слои для нейронной сети\n",
    "from keras.models import Model # Keras модель (не последовательная)\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping # callback функции\n",
    "import keras # для работы с моделью\n",
    "\n",
    "import matplotlib.pyplot as plt # для построения графиков\n",
    "import time # для отслеживания времени выполнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./data/\" # путь до папки с данными\n",
    "EMBEDDING_DIR = \"./embeddings/\" # путь до папки с эмбеддингами\n",
    "MODELS_DIR = \"./models/\" # путь до папки с моделями\n",
    "RANDOM_STATE = 42 # число для задания случайности\n",
    "DTYPE = np.float32 # используемый тип\n",
    "\n",
    "MAX_WORDS_TOKENIZER = None # ограничение на число слов в словаре токенизатора (None — без ограничения)\n",
    "MAX_LEN = 39 # оптимальное число токенов в документе (если не достаёт — padding, если перебор — truncation), определялось по гистограмме распределения числа токенов в текстах\n",
    "ENCODING_DIM = 256  # итоговая размерность пространства, в которое будет преобразован выход энкодера (такая же размерность входа у декодера)\n",
    "EMBEDDING_DIM = 300 # размерность вектора-эмбеддинга слова\n",
    "\n",
    "EPOCHS_PATIENCE = 50 # число эпох без изменения наблюдаемой метрики, после которого обучение прекратится\n",
    "EPOCHS = 500 # число эпох обучения\n",
    "LEARNING_RATE = 0.001 # learning rate\n",
    "BATCH_SIZE = 10 # размер батча (число сэмплов, передаваемых в модель одновременно => чем больше значение - тем быстрее обучение, но хуже качество из-за аккумуляции градиентов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toxic comment</th>\n",
       "      <th>Polite comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>почитай посты у этого автора, дебил.</td>\n",
       "      <td>попробуйте почитать посты этого автора, может ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>мне жаль тебя, гандон, если для тебя оскорблен...</td>\n",
       "      <td>извините, но мне вас очень жаль, если для вас ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>тебе в говне ходить нормально, урод?</td>\n",
       "      <td>извини, но приятно бы тебе было ходить в грязном?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>блять, я согласен, что энергия от виэ на текущ...</td>\n",
       "      <td>я согласен с вами, что энергия от виэ на текущ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>я этим сраным ватсаппом никогда не пользовался...</td>\n",
       "      <td>просто я, к сожалению, ватсаппом никогда не по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Пошел нахуй с тупичка</td>\n",
       "      <td>Уходите с тупичка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Да уж, ебаные татары русское население мягко г...</td>\n",
       "      <td>Да уж, татары русское население мягко говоря н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Умный дурак в два раза опасней</td>\n",
       "      <td>Умный глупец в два раза опасней</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Это беседа одного того самого имбецила?</td>\n",
       "      <td>Это беседа одного того самого человека?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Да и хер с ними, спорт дерьмо</td>\n",
       "      <td>Да и бог с ними, спорт ужасен</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Toxic comment  \\\n",
       "0                почитай посты у этого автора, дебил.    \n",
       "1    мне жаль тебя, гандон, если для тебя оскорблен...   \n",
       "2                 тебе в говне ходить нормально, урод?   \n",
       "3    блять, я согласен, что энергия от виэ на текущ...   \n",
       "4    я этим сраным ватсаппом никогда не пользовался...   \n",
       "..                                                 ...   \n",
       "194                              Пошел нахуй с тупичка   \n",
       "195  Да уж, ебаные татары русское население мягко г...   \n",
       "196                     Умный дурак в два раза опасней   \n",
       "197            Это беседа одного того самого имбецила?   \n",
       "198                      Да и хер с ними, спорт дерьмо   \n",
       "\n",
       "                                        Polite comment  \n",
       "0    попробуйте почитать посты этого автора, может ...  \n",
       "1    извините, но мне вас очень жаль, если для вас ...  \n",
       "2    извини, но приятно бы тебе было ходить в грязном?  \n",
       "3    я согласен с вами, что энергия от виэ на текущ...  \n",
       "4    просто я, к сожалению, ватсаппом никогда не по...  \n",
       "..                                                 ...  \n",
       "194                                  Уходите с тупичка  \n",
       "195  Да уж, татары русское население мягко говоря н...  \n",
       "196                    Умный глупец в два раза опасней  \n",
       "197            Это беседа одного того самого человека?  \n",
       "198                      Да и бог с ними, спорт ужасен  \n",
       "\n",
       "[199 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_excel(DATA_DIR + \"dataset_200.xls\", index_col=None) # считывание excel данных (index_col — какой столбец из данных использовать как индексы в DataFrame)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление токенов старта и конца."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> почитай посты у этого автора , дебил . <end>',\n",
       " '<start> мне жаль тебя , гандон , если для тебя оскорбления - норма . <end>',\n",
       " '<start> тебе в говне ходить нормально , урод ? <end>',\n",
       " '<start> блять , я согласен , что энергия от виэ на текущий момент дороже . но объясните мне , нахуя правительства всех стран мира стараются развить эту ебанину ? ! нахрена развивать нечто , заведомо убыточное ? ! <end>',\n",
       " '<start> я этим сраным ватсаппом никогда не пользовался , а теперь придется ставить ради одного дебильного турнира . пиздец <end>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Toxic comment\"] = dataset[\"Toxic comment\"].apply(lambda text: word_tokenize(text)) # разбиваем текст на слова (токены)\n",
    "dataset[\"Toxic comment\"] = dataset[\"Toxic comment\"].apply(lambda sequence: [\"<start>\"] + sequence + [\"<end>\"]) # добавление токенов старта (<start>) и конца (<end>)\n",
    "dataset[\"Toxic comment\"] = dataset[\"Toxic comment\"].apply(lambda sequence: \" \".join(sequence)) # собираем последовательность слов обратно в строку, но теперь даже служебные символы разделены пробелами\n",
    "\n",
    "dataset[\"Polite comment\"] = dataset[\"Polite comment\"].apply(lambda text: word_tokenize(text)) # разбиваем текст на слова (токены)\n",
    "dataset[\"Polite comment\"] = dataset[\"Polite comment\"].apply(lambda sequence: [\"<start>\"] + sequence + [\"<end>\"]) # добавление токенов старта (<start>) и конца (<end>)\n",
    "dataset[\"Polite comment\"] = dataset[\"Polite comment\"].apply(lambda sequence: \" \".join(sequence)) # собираем последовательность слов обратно в строку, но теперь даже служебные символы разделены пробелами\n",
    "\n",
    "texts = dataset[\"Toxic comment\"].tolist() + dataset[\"Polite comment\"].tolist() # собираем все текста в один список\n",
    "texts[:5] # пример первых пяти получившихся элементов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конвертация строк (документов) в последовательности токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_WORDS_TOKENIZER, filters='', lower=True, split=\" \", char_level=False, oov_token='<OOV>') # создаём объект токенизатора, без ограничения числа токенов (num_words=None)\n",
    "tokenizer.fit_on_texts(texts) # обучаем токенизатор на текстах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число уникальных слов в корпусе: 1316.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('<OOV>', 1),\n",
       " (',', 2),\n",
       " ('<start>', 3),\n",
       " ('<end>', 4),\n",
       " ('.', 5),\n",
       " ('?', 6),\n",
       " ('не', 7),\n",
       " ('и', 8),\n",
       " ('что', 9),\n",
       " ('в', 10)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id = tokenizer.word_index # словарь соответствия слова его id_шнику (не ограничены MAX_FEATURES)\n",
    "id2word = tokenizer.index_word # словарь соответствия id_шника слову (не ограничены MAX_FEATURES)\n",
    "\n",
    "vocab_size = len(id2word) # число слов в корпусе\n",
    "docs_count = len(dataset) # число документов в корпусе\n",
    "\n",
    "print(f\"Число уникальных слов в корпусе: {vocab_size}.\") # включая специальные токены\n",
    "list(word2id.items())[:10] # первые 10 элементов словаря конвертации слова в токен (id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример токенизации документа: [3, 197, 1134, 60, 56, 256, 2, 78, 238, 38, 1135, 1136, 117, 215, 1137, 5, 113, 2, 16, 1138, 1139, 31, 4].\n"
     ]
    }
   ],
   "source": [
    "encoded_toxic = tokenizer.texts_to_sequences(dataset[\"Toxic comment\"]) # токенизируем документы\n",
    "encoded_polite = tokenizer.texts_to_sequences(dataset[\"Polite comment\"]) # токенизируем документы\n",
    "\n",
    "print(f\"Пример токенизации документа: {encoded_polite[0]}.\") # пример токенизации первого документа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример получившегося преобразования в токены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 — <start>\n",
      "197 — попробуйте\n",
      "1134 — почитать\n",
      "60 — посты\n",
      "56 — этого\n",
      "256 — автора\n",
      "2 — ,\n",
      "78 — может\n",
      "238 — быть\n",
      "38 — вам\n",
      "1135 — удастся\n",
      "1136 — найти\n",
      "117 — там\n",
      "215 — что-то\n",
      "1137 — полезное\n",
      "5 — .\n",
      "113 — надеюсь\n",
      "2 — ,\n",
      "16 — я\n",
      "1138 — смог\n",
      "1139 — помочь\n",
      "31 — )\n",
      "4 — <end>\n"
     ]
    }
   ],
   "source": [
    "for token in encoded_polite[0]: # идём по токенам примера 0\n",
    "    print(f\"{token} — {id2word[token]}\") # выводи токен (id) и соответствующее ему слово"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведение последовательностей токенов к одной длине (размерности)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная длина документа в токенах: 39.\n"
     ]
    }
   ],
   "source": [
    "lengths = [] # список под длины документов в токенах\n",
    "for doc in encoded_toxic + encoded_polite: # идём по токенизированным документам\n",
    "    lengths.append(len(doc)) # добавляем число токенов в документе в список\n",
    "\n",
    "print(f\"Максимальная длина документа в токенах: {max(lengths)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8)) # задание размера фигуры\n",
    "plt.hist(lengths, bins=20) # построение столбчатой диаграммы по данным\n",
    "plt.title(\"Распределение длин документов в токенах\") # название фигуры\n",
    "plt.xlabel(\"Длина документа\") # подпись по оси x\n",
    "plt.ylabel(\"Количество записей\") # подпись по оси y\n",
    "plt.show() # показ фигуры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Финальная размерность токенизированных документов: сэмплов — 199, токенов — 39.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   3,  197, 1134, ...,    0,    0,    0],\n",
       "       [   3,  198,    2, ...,    0,    0,    0],\n",
       "       [   3,  216,    2, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   3,  844, 1314, ...,    0,    0,    0],\n",
       "       [   3,   23,  848, ...,    0,    0,    0],\n",
       "       [   3,   27,    8, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_toxic = pad_sequences(encoded_toxic, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\", value=0) # приводим вектора токенов к единой размерности MAX_LEN с помощью padding_а и truncating_а (заполняем значением value)\n",
    "padded_polite = pad_sequences(encoded_polite, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\", value=0) # приводим вектора токенов к единой размерности MAX_LEN с помощью padding_а и truncating_а (заполняем значением value)\n",
    "\n",
    "print(f\"Финальная размерность токенизированных документов: сэмплов — {padded_polite.shape[0]}, токенов — {padded_polite.shape[1]}.\")\n",
    "padded_polite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word[0] = \"<pad>\" # добавление токена пропуска (<pad>) под индексом 0\n",
    "word2id[\"<pad>\"] = 0 # добавление токена пропуска (<pad>) под индексом 0\n",
    "vocab_size += 1 # увеличение размера словаря под токен паддинга (идёт под индексом 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = np.zeros(shape=(docs_count, MAX_LEN, vocab_size), dtype=DTYPE) # трёхмерный массив размерности (число документов, число токенов в документе, размер словаря) — таргеты (вероятности слова-токена word_id, что является t-ым токеном в d-м документе)\n",
    "for d, doc_tokenized in enumerate(padded_polite): # идём по документам в корпусе\n",
    "    for t, word_id in enumerate(doc_tokenized[1:]): # идём по токенам в документе (пропуская первый, <start>, так как он и так будет предоставлен)\n",
    "        if word_id > 0: # если токен не нулевой (паддинга)\n",
    "            target_data[d][t][word_id] = 1 # ставим ему вероятность = 1 (у всех остальных будут нулю на размерности, отвечающей за vocab_size)\n",
    "            # у всех токенов, что имеют значение паддинга, вероятности будут равные нулю (чтобы в них вообще ничего не предсказывалось)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data # вероятности слов на каждой позиции токена в документах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример разницы входа у декодера и ожидаемого выхода (argmax по вероятностям слов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   3,  197, 1134,   60,   56,  256,    2,   78,  238,   38, 1135,\n",
       "       1136,  117,  215, 1137,    5,  113,    2,   16, 1138, 1139,   31,\n",
       "          4,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_polite[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 197, 1134,   60,   56,  256,    2,   78,  238,   38, 1135, 1136,\n",
       "        117,  215, 1137,    5,  113,    2,   16, 1138, 1139,   31,    4,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(target_data[0], axis=1) # пример таргетов (axis=1 - по столбцам, то есть вероятностям слов на позиции токена t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Эмбеддинги"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для получения векторов-эмбеддингов воспользуемся [***Navec***](https://github.com/natasha/navec?tab=readme-ov-file), так как он компактный (легко умещается в память оперативную/физическую), хоть и имеет огромный словарь, и заточен под работу с русским языком. Словарь Navec содержит 500000 слов, представленных в виде векторов размерности 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "navec = Navec.load(f\"{EMBEDDING_DIR}navec_hudlit_v1_12B_500K_300d_100q.tar\") # загружаем вектора\n",
    "# navec_hudlit_v1_12B_500K_300d_100q.tar\n",
    "#                  |    |    |    |\n",
    "#                  |    |    |     ---- 100 dimentions after quantization\n",
    "#                  |    |     --------- original vectors have 300 dimentions\n",
    "#                  |     -------------- vocab size is 500 000 words + 2 for <unk>, <pad>\n",
    "#                   ------------------- dataset of 12 billion tokens was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.22543699, -0.39721358,  0.6805563 ,  0.21706595, -0.19716908,\n",
       "       -0.20722607, -0.07350219,  0.13129961, -0.17141329,  0.09088685,\n",
       "        0.21599719, -0.09282316,  0.00766279, -0.11043157, -0.07346303,\n",
       "        0.42286018, -0.26629096,  0.31371886, -0.08937341,  0.09485467,\n",
       "       -0.04480258, -0.44643393, -0.3061798 , -0.2882515 ,  0.5377174 ,\n",
       "        0.36234093,  0.0030303 ,  0.23453966, -0.28672412, -0.20668298,\n",
       "       -0.19193137,  0.04902396,  0.8125157 ,  0.5318507 , -0.6188356 ,\n",
       "       -0.04572238, -0.02173791, -0.66719943, -0.7230108 , -0.2762196 ,\n",
       "       -0.23562106,  0.5413357 , -0.05294172,  0.6201654 , -0.8374897 ,\n",
       "       -0.36382714,  0.4649254 , -0.13510832,  0.09727751, -0.10602053,\n",
       "        0.37899598, -0.36541265, -0.20060915,  0.10681065, -0.5519943 ,\n",
       "       -0.13753682, -0.01502502,  0.09474958, -0.05980838, -0.02857767,\n",
       "       -0.55855787, -0.04823827, -0.3578416 ,  0.88438463,  0.32023084,\n",
       "       -0.25467572,  0.22748815, -0.6873215 , -0.04857488, -0.7444249 ,\n",
       "       -0.41156083,  0.19128552,  0.07123397, -0.14737812, -0.39385885,\n",
       "       -0.24628565,  0.5453377 , -0.05320076,  0.06201499, -0.04103868,\n",
       "       -0.2932616 ,  0.3779095 , -0.31397003, -0.04615191, -0.43017006,\n",
       "       -0.00623761,  0.61113805,  0.2079509 , -0.05063467,  0.09398386,\n",
       "       -0.41160762,  0.09362367, -0.8432128 , -0.10191941,  0.01678637,\n",
       "        0.6130639 , -0.50620526,  0.06421215,  0.15180896, -1.001532  ,\n",
       "       -0.29364854, -0.1847418 ,  0.05156467, -0.23999164,  0.49402934,\n",
       "        0.34105918, -0.8930306 , -0.09359165,  0.5060184 ,  0.56454605,\n",
       "       -0.21829388,  0.05214137, -0.5776496 ,  0.13659137, -0.3143733 ,\n",
       "        0.12403905,  0.11754724,  0.09411987,  0.27510226, -0.05934107,\n",
       "       -0.39489806, -0.2788272 , -0.03585588,  0.39080086,  0.01645428,\n",
       "        0.00155893, -0.6858619 ,  0.03199653, -0.23169942, -0.57183355,\n",
       "        0.7449328 , -0.2478331 , -0.0656902 , -0.23359276, -0.15860626,\n",
       "        0.46892813,  0.25094634, -0.0038072 ,  0.8120501 , -0.3921491 ,\n",
       "        0.53953594,  0.0864343 ,  0.16530593, -0.34294814, -0.660825  ,\n",
       "        0.17502032,  0.1601436 ,  0.12880398,  0.2447404 , -0.1398195 ,\n",
       "        0.3940808 , -0.20316295,  0.40920585,  0.30853412,  0.24878557,\n",
       "       -0.08787356, -0.00201242, -0.0976093 ,  0.24608812, -0.20107856,\n",
       "       -0.08510465, -0.22498815, -0.24412297,  0.11659407, -0.23810975,\n",
       "        0.7927576 , -0.19332255,  0.35179833,  0.1266067 , -0.22534452,\n",
       "        0.22342923,  0.52875555, -0.13713977,  0.5322976 , -0.01586652,\n",
       "       -0.36773518,  0.18660183, -0.15345146, -0.6563604 ,  0.03934827,\n",
       "       -0.2537932 ,  0.5915523 ,  0.17447926,  0.08440425, -0.14555511,\n",
       "        0.8462292 ,  0.02306626, -0.50092953,  0.02497473,  0.09709087,\n",
       "        0.42852387, -0.12507445, -0.43765643, -0.04486881, -0.9197812 ,\n",
       "        0.15333776,  0.21755728,  0.16034487,  0.10947693,  0.26935494,\n",
       "        0.08937906, -0.32551923,  0.30181772,  0.03085733,  0.32175773,\n",
       "        0.58648676, -0.4552861 , -0.09058901, -0.07721699,  0.13540809,\n",
       "       -0.00645914, -0.24767125, -0.17353976, -0.32662928,  0.55255526,\n",
       "       -0.31210357,  0.71981466, -0.35557505, -0.2027955 ,  0.5551026 ,\n",
       "       -0.30438095, -0.41725138, -0.4683033 ,  0.03520601,  0.67806554,\n",
       "       -0.02468547,  0.33984688,  0.43193454, -0.27096793, -0.02520603,\n",
       "        0.286634  , -0.02133529, -0.55753946,  0.2741532 ,  0.21432668,\n",
       "       -0.4251435 ,  0.3402687 ,  0.3789248 ,  0.38285363, -0.01478797,\n",
       "        0.4644731 ,  0.21247226, -0.6237922 , -0.14217526, -0.36516917,\n",
       "        0.14149092, -0.15003966,  0.07534812, -0.26868176,  0.23520207,\n",
       "       -0.54361004, -0.9098788 , -0.3157734 ,  0.18669239, -0.0962809 ,\n",
       "       -0.37809882,  0.4742351 ,  0.13234845, -0.50550336,  0.17703918,\n",
       "       -0.44975471,  0.19239506,  0.30779085,  0.24575497,  0.5954058 ,\n",
       "        0.45039576, -0.16555037,  0.11469514, -0.0700791 ,  0.00519014,\n",
       "        0.64192   , -0.07611681, -0.04211494, -0.04530421, -0.69490165,\n",
       "       -0.5775567 , -0.34478965, -0.05541408,  0.5040086 ,  0.14443237,\n",
       "       -0.49850866,  0.23184095,  0.10807174, -0.06104805,  0.24632384,\n",
       "        0.4157553 , -0.3786785 , -0.18116818,  0.5042701 ,  0.6235093 ,\n",
       "        0.28725666, -0.41006738, -0.27313936, -0.1506457 , -0.24990621,\n",
       "       -0.3762372 ,  0.15003653, -0.05707216,  0.10502052,  0.30300924],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navec.get(\"россия\") # пример работы Navec (возвращает np.array типа float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполняем матрицу эмбеддингов векторами, соответствующими словам (или нулями, если слова нет в словаре Navec, они позже будут дообучены в модели)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропущенно 170 слов из 1317.\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM)) # создаём матрицу из нулей под эмбеддинги слов (+1 — для вектора паддинга, что будет идти под индексом 0)\n",
    "\n",
    "skipped_words = [] # список под слова без вектора\n",
    "for i in range(1, vocab_size): # идём по числу слов (токенов), начиная с 1, так как 0 под padding и до vocab_size не включительно (чтобы уместить все слова)\n",
    "    word = id2word[i] # слово, что идёт под номером i в токенизаторе\n",
    "    if navec.get(word) is not None: # если у рассматриваемого слова есть вектор в Navec (иначе вернёт None)\n",
    "        embedding_matrix[i] = navec.get(word) # записываем i-ый вектор в матрицу эмбеддингов\n",
    "    else: # если слова нет в Navec\n",
    "        skipped_words.append(word) # добавляем слово в список пропущенных\n",
    "\n",
    "print(f\"Пропущенно {len(skipped_words)} слов из {vocab_size}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа с моделью"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![seq2seq model](images/seq2seq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основная структура модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">395,100</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">395,100</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">570,368</span> │ encoder_embeddin… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">570,368</span> │ decoder_embeddin… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ word_probs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1317</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">338,469</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │    \u001b[38;5;34m395,100\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │    \u001b[38;5;34m395,100\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m570,368\u001b[0m │ encoder_embeddin… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m570,368\u001b[0m │ decoder_embeddin… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ word_probs (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m1317\u001b[0m)  │    \u001b[38;5;34m338,469\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,269,405</span> (8.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,269,405\u001b[0m (8.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,269,405</span> (8.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,269,405\u001b[0m (8.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# энкодер (на вход идут токсичные сообщения)\n",
    "encoder_input = Input(shape=(MAX_LEN,), dtype=DTYPE, name='encoder_input') # входной слой энкодера, получает вектор размера (BATCH_SIZE, число слов или токенов в входных данных)\n",
    "encoder_embedding = Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, name='encoder_embedding')(encoder_input) # слой эмбеддинга (на вход — encoder_input размера словаря input_dim, выход размерности (BATCH_SIZE, число токенов в документе, размерность вектора-эмбеддинга))\n",
    "encoder_output, encoder_hidden_state, encoder_context = LSTM(units=ENCODING_DIM, return_state=True, name='encoder_lstm')(encoder_embedding) # слой LSTM, return_state — возвращающий помимо выхода слоя, также свой hidden_state и вектор context_а\n",
    "encoder_state = [encoder_hidden_state, encoder_context] # запоминаем hidden_state и вектор context_а энкодера (пойдут как начальное состояние декодера)\n",
    "# РАБОТА С ВЫХОДОМ ЭНКОДЕРА БОЛЬШЕ НЕ ВЕДЁТСЯ, А ТОЛЬКО С ЕГО СОСТОЯНИЕМ ПРИ ВЫХОДЕ\n",
    "\n",
    "# декодер (на вход идут нетоксичные сообщения)\n",
    "decoder_input = Input(shape=(MAX_LEN,), dtype=DTYPE, name='decoder_input') # входной слой декодера, получает вектор размера (BATCH_SIZE, число слов или токенов в выходных данных)\n",
    "decoder_embedding_layer = Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, name='decoder_embedding') # слой эмбеддинга (на вход — decoder_input размера словаря input_dim, выход размерности (BATCH_SIZE, число токенов в документе, размерность вектора-эмбеддинга))\n",
    "decoder_embedding = decoder_embedding_layer(decoder_input) # вызов слоя эмбеддинга\n",
    "decoder_lstm_layer = LSTM(units=ENCODING_DIM, return_sequences=True, return_state=True, name='decoder_lstm') # слой LSTM, return_state — возвращающий помимо выхода слоя, также свой hidden_state и вектор context_а; return_sequences — возвращать лишь последний выход или выходы для всй входной последовательности (True - чтобы предсказывать целую последовательность, иначе было бы лишь одно число)\n",
    "decoder_lstm, _, _ = decoder_lstm_layer(decoder_embedding, initial_state=encoder_state) # вызываем слой LSTM с передачей внутреннего состояния из энкодера\n",
    "decoder_dense = Dense(units=vocab_size, activation=\"softmax\", name='word_probs') # линейный слой с \"softmax\" для получения вероятностей слов (units=vocab_size) на позиции токена t, а так как LSTM возвращает последовательность (return_sequences=True) - выходом будет трёхмерная матрица (BATCH_SIZE, число токенов в документе, размер словаря)\n",
    "decoder_output = decoder_dense(decoder_lstm) # вызываем линейный слой\n",
    "\n",
    "# общая модель\n",
    "model = Model(inputs=[encoder_input, decoder_input], outputs=decoder_output) # финальное объединение в одну модель\n",
    "\n",
    "model.summary() # вывод данных о модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Устанавливаем специфичные веса и параметры обучения для слоя эмбеддинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<InputLayer name=encoder_input, built=True>,\n",
       " <InputLayer name=decoder_input, built=True>,\n",
       " <Embedding name=encoder_embedding, built=True>,\n",
       " <Embedding name=decoder_embedding, built=True>,\n",
       " <LSTM name=encoder_lstm, built=True>,\n",
       " <LSTM name=decoder_lstm, built=True>,\n",
       " <Dense name=word_probs, built=True>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2].set_weights([embedding_matrix]) # устанавливаем вектора эмбеддингов\n",
    "# model.layers[2].trainable = False # ставим флаг, что слой не будет обучаться\n",
    "model.layers[3].set_weights([embedding_matrix]) # устанавливаем вектора эмбеддингов\n",
    "# model.layers[3].trainable = False # ставим флаг, что слой не будет обучаться"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_early_stopping():\n",
    "    \"\"\"\n",
    "    This function should return an EarlyStopping callback that stops learning when the\n",
    "    validation (testing) accuracy has not improved over the last N epochs.\n",
    "    \"\"\"\n",
    "    early_stopping = EarlyStopping(monitor=\"loss\", mode=\"min\", patience=EPOCHS_PATIENCE) # callback ранней остановки обучения\n",
    "    # monitor — по какой метрике судить, нужно ли прекращать обучение, например - val_loss\n",
    "    # mode — метрика должна увеличиваться (max) или уменьшаться (min)\n",
    "    # patience — сколько должно пройти эпох без улучшения отслеживаемой метрики чтобы прекратить обучение\n",
    "    return early_stopping\n",
    "\n",
    "\n",
    "def get_checkpoint_best_only():\n",
    "    \"\"\"\n",
    "    This function should return a ModelCheckpoint object that:\n",
    "    - stores only those weights of the neural network that generate the highest accuracy during testing\n",
    "    - saves to the 'checkpoints_best_only' directory inside the current working directory\n",
    "    - generates a file named '{MODELS_DIR}best_model.keras'\n",
    "    \"\"\"\n",
    "    checkpoint_best = ModelCheckpoint(filepath=f\"{MODELS_DIR}best_model.keras\", save_best_only=True, save_weights_only=False, monitor=\"loss\", mode=\"min\") # callback сохранения чекпоинтов модели\n",
    "    # filepath — путь до файла, куда сохранять (можно с указанием эпохи...)\n",
    "    # save_best_only — сохранять только если результат (отслеживаемая метрика) улучшилась\n",
    "    # save_weights_only — сохранять ли только веса\n",
    "    # monitor — по какой метрике судить, стала ли модель лучше/хуже\n",
    "    # mode — метрика должна увеличиваться (max) или уменьшаться (min)\n",
    "    return checkpoint_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сборка модели с обучением"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Переобучение для моделей генерации и перевода (детоксикации) текста на самом деле положительно сказывается на её ответах.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=None) # компилирование модели с указанием оптимизатора, функции потерь и дополнительных метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_checkpoint = get_checkpoint_best_only() # callback сохранения чекпоинтов\n",
    "callback_stopping = get_early_stopping() # callback ранней остановки обучения\n",
    "\n",
    "callbacks = [callback_checkpoint, callback_stopping] # список callback_ов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - loss: 2.2784\n",
      "Epoch 2/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 151ms/step - loss: 1.9085\n",
      "Epoch 3/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - loss: 1.8917\n",
      "Epoch 4/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 1.9180\n",
      "Epoch 5/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - loss: 1.8411\n",
      "Epoch 6/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.8438\n",
      "Epoch 7/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 1.8422\n",
      "Epoch 8/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.7609\n",
      "Epoch 9/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - loss: 1.8794\n",
      "Epoch 10/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 1.8332\n",
      "Epoch 11/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.8401\n",
      "Epoch 12/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.7747\n",
      "Epoch 13/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 164ms/step - loss: 1.8128\n",
      "Epoch 14/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - loss: 1.7362\n",
      "Epoch 15/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - loss: 1.6574\n",
      "Epoch 16/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - loss: 1.7259\n",
      "Epoch 17/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - loss: 1.6439\n",
      "Epoch 18/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 1.6828\n",
      "Epoch 19/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 1.6463\n",
      "Epoch 20/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - loss: 1.7046\n",
      "Epoch 21/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.7540\n",
      "Epoch 22/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - loss: 1.7245\n",
      "Epoch 23/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - loss: 1.7616\n",
      "Epoch 24/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - loss: 1.6856\n",
      "Epoch 25/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.7477\n",
      "Epoch 26/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - loss: 1.6920\n",
      "Epoch 27/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 1.6990\n",
      "Epoch 28/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 1.6644\n",
      "Epoch 29/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 1.5603\n",
      "Epoch 30/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - loss: 1.6392\n",
      "Epoch 31/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 1.6214\n",
      "Epoch 32/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - loss: 1.5595\n",
      "Epoch 33/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 1.6535\n",
      "Epoch 34/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - loss: 1.6515\n",
      "Epoch 35/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 1.6982\n",
      "Epoch 36/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.6358\n",
      "Epoch 37/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5650\n",
      "Epoch 38/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 1.5894\n",
      "Epoch 39/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 170ms/step - loss: 1.6248\n",
      "Epoch 40/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.5394\n",
      "Epoch 41/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 1.5527\n",
      "Epoch 42/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.6000\n",
      "Epoch 43/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 1.7007\n",
      "Epoch 44/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 1.4884\n",
      "Epoch 45/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 1.6450\n",
      "Epoch 46/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 1.5374\n",
      "Epoch 47/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5058\n",
      "Epoch 48/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.5558\n",
      "Epoch 49/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 1.5464\n",
      "Epoch 50/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.5547\n",
      "Epoch 51/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.4997\n",
      "Epoch 52/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 170ms/step - loss: 1.4629\n",
      "Epoch 53/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 1.5251\n",
      "Epoch 54/500\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - loss: 1.5639\n",
      "Epoch 55/500\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 1.5940"
     ]
    }
   ],
   "source": [
    "time_start = time.time() # замеряем время начала обучения\n",
    "\n",
    "history = model.fit(x=[padded_toxic, padded_polite], y=target_data, validation_data=None, validation_split=0, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks, verbose=1) # запускаем обучение модели (результатом которого будет история изменения метрик)\n",
    "# x — вход модели (а данном случае — двойной)\n",
    "# y — таргеты\n",
    "# epochs — число эпох обучения\n",
    "# batch_size — размер батчка\n",
    "# validation_data — тестовые данные (тестовый двойной вход и его таргеты)\n",
    "# validation_split — если validation_data=None, то validation_split определяет, какой процент данных будет использован для валидации (на нём не будет обучения), например 0.2\n",
    "# callbacks — список callback функций\n",
    "# verbose — на сколько подробно выводить информацию об обучении (1 - на каждой эпохе)\n",
    "\n",
    "print(f\"Время, затраченное на обучение: {time.time()  - time_start} секунд.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history # словарь с историей обучения\n",
    "print(history_dict.keys()) # ключи в словаре истории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6)) # задание размера графика\n",
    "epochs = range(1, len(history_dict['loss']) + 1) # число эпох обучения (сколько было сохранено значений loss)\n",
    "plt.plot(epochs, history_dict[\"loss\"], 'b', label='Training loss') # построение линейного графика ('b' — синего цвета)\n",
    "plt.title(\"Изменение значения loss функции в зависимости от эпохи обучения\") # название фигуры\n",
    "plt.xlabel('Эпоха') # подпись по оси OX\n",
    "plt.ylabel('loss') # подпись по оси OY\n",
    "plt.legend() # вывод подписей для графиков\n",
    "plt.show() # показ фигуры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{MODELS_DIR}final_model.keras\") # сохранение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем сохранённую модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<InputLayer name=encoder_input, built=True>,\n",
       " <InputLayer name=decoder_input, built=True>,\n",
       " <Embedding name=encoder_embedding, built=True>,\n",
       " <Embedding name=decoder_embedding, built=True>,\n",
       " <LSTM name=encoder_lstm, built=True>,\n",
       " <LSTM name=decoder_lstm, built=True>,\n",
       " <Dense name=word_probs, built=True>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(f\"{MODELS_DIR}best_model.keras\") # загружаем сохранённую модель\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы грузим модель извне, то нужно описать входы, выходы и промежуточный вектор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Энкодер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = model.input[0] # вход энкодера\n",
    "\n",
    "#=================================== v1 ========================================\n",
    "# encoder_output, *encoder_state = model.layers[4].output # выход энкодера (из LSTM), hidden_state и context сразу записываем в encoder_state\n",
    "#----------------------------------- v2 ----------------------------------------\n",
    "encoder_embedding = model.layers[2](encoder_input) # вызываем слой эмбеддинга энкодера\n",
    "encoder_output, *encoder_state = model.layers[4](encoder_embedding) # вызываем слой LSTM энкодера, hidden_state и context сразу записываем в encoder_state\n",
    "#===============================================================================\n",
    "\n",
    "encoder_model = Model(inputs=encoder_input, outputs=encoder_state) # модель энкодера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<InputLayer name=encoder_input, built=True>,\n",
       " <Embedding name=encoder_embedding, built=True>,\n",
       " <LSTM name=encoder_lstm, built=True>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model.layers # получили обратно все слои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Декодер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = model.input[1] # вход декодера\n",
    "\n",
    "decoder_hidden_state = Input(shape=(ENCODING_DIM,), name='decoder_hidden_state') # hidden_state декодера идёт сначала пустым\n",
    "decoder_context = Input(shape=(ENCODING_DIM,), name='decoder_context') # context вектор декодера идёт сначала пустым\n",
    "decoder_state_input = [decoder_hidden_state, decoder_context] # запоминаем hidden_state и вектор context_а декодера (пойдут как начальное состояние)\n",
    "\n",
    "# decoder_embedding = decoder_embedding_layer(decoder_input) # вызываем слой эмбеддинга декодера\n",
    "decoder_embedding = model.layers[3](decoder_input) # вызываем слой эмбеддинга декодера\n",
    "\n",
    "# decoder_lstm, *decoder_state = decoder_lstm_layer(decoder_embedding, initial_state=decoder_state_input) # вызываем слой LSTM декодера, hidden_state и context сразу записываем в encoder_state\n",
    "decoder_lstm, *decoder_state = model.layers[5](decoder_embedding, initial_state=decoder_state_input) # вызываем слой LSTM декодера, hidden_state и context сразу записываем в encoder_state\n",
    "\n",
    "# decodet_output = decoder_dense(decoder_lstm) # вызываем линейный слой для получения вероятностей слов\n",
    "decodet_output = model.layers[6](decoder_lstm) # вызываем линейный слой для получения вероятностей слов\n",
    "\n",
    "decoder_model = Model(inputs=[decoder_input] + decoder_state_input, outputs=[decodet_output] + decoder_state) # модель декодера с нексолькими данными на вход (токены и state) и выход (вероятности слов на позициях и state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<InputLayer name=decoder_input, built=True>,\n",
       " <Embedding name=decoder_embedding, built=True>,\n",
       " <InputLayer name=decoder_hidden_state, built=True>,\n",
       " <InputLayer name=decoder_context, built=True>,\n",
       " <LSTM name=decoder_lstm, built=True>,\n",
       " <Dense name=word_probs, built=True>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_model.layers # получили обратно все слои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Детоксикация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# процедура декодирования последовательности\n",
    "def decode_sequence(input_seq) -> str:\n",
    "    \"\"\"\n",
    "    Функция для конвертированя вероятностей токенов на каждой позиции в слова.\\n\n",
    "    Parameters:\n",
    "        * input_seq: входная последовательность для энкодера (список токенов)\\n\n",
    "    Returns:\n",
    "        * str: декодированная строка\n",
    "    \"\"\"\n",
    "    state = encoder_model.predict(input_seq) # делаем предсказание по токенам при помощи энкодера и получаем на выходе его state\n",
    "\n",
    "    # создаём \"вектор\" таргетов, что пойдёт на вход декодеру, начинается с токена <start> (будет передаваться в модель, пока не сгенерируется токен окончания предсказания)\n",
    "    target_seq = np.zeros((1, 1)) # создадим пустой вектор, который будет содержать нашу предсказанную последовательнось, размерности (BATCH_SIZE=1, токены таргета)\n",
    "    target_seq[0, 0] = word2id[\"<start>\"] # первый символ target последовательности будет токен \"<start>\"\n",
    "\n",
    "    # проводим процедуру генерации токенов\n",
    "    stop_condition = False # ключ для выхода генерации перевода\n",
    "    decoded_sentence = \"\" # строка получившегося перевода\n",
    "    decoded_counter = 0 # счётчик числа декодированных токенов\n",
    "    while not stop_condition: # пока не выполнено условие прекращения генерации\n",
    "        # генерируем текущий токен на основе пока пустой target последовательности (в ней только токен <start>) и state из энкодера\n",
    "        # процес повторяется, шаг за шагом, в ходе итерауий модель генерируем последовальность токенов\n",
    "        output_tokens, *state = decoder_model.predict([target_seq] + state) # декодируем последовательность с учётом внутреннего состояния\n",
    "\n",
    "        pred_token = np.argmax(output_tokens[0, -1, :]) # определяем id самого вероятного токена (0 — так как BATCH_SIZE=1 при инференсе, -1 — токен на последней сгенерированной позиции, : — среди всех вероятности слов)        \n",
    "        pred_word = id2word[pred_token] # определяем слово на основе его id (токена)\n",
    "        target_seq[0, 0] = pred_token # обновляем target последовательность за счет нового токена для следующего шага\n",
    "\n",
    "        if pred_word in [\"<end>\", \"<pad>\"] or decoded_counter >= MAX_LEN: # условие остановки — достижение максимальной длины (числа токенов), либо найдены токены <end> или <pad>\n",
    "            stop_condition = True # меняем флаг прекращения генерации токенов\n",
    "        else:\n",
    "            decoded_sentence += f\" {pred_word}\" # добавляем слово в конец полученной декодируемой строки с пробелом\n",
    "            decoded_counter += 1 # обновляем счётчик декодированных токенов в последовательности\n",
    "\n",
    "    decoded_sentence = re.sub(r'\\s+(?=(?:[,.?!:;…]))', r'', decoded_sentence) # удаляем пробелы перед знаками препинания\n",
    "    return decoded_sentence.strip() # возвращаем строку без пробелов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токсичный текст: Ты долбоёб, сначала про тему почитай, а только высерай свои буквы!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Обработанный текст: вы просто не умеете читать между строк.\n"
     ]
    }
   ],
   "source": [
    "text = \"Ты долбоёб, сначала про тему почитай, а только потом пробуй писать!\" # приходящий текст\n",
    "print(f\"Токсичный текст: {text}\")\n",
    "\n",
    "sequence = word_tokenize(text) # разбиваем текст на слова (токены)\n",
    "sequence = [\"<start>\"] + sequence + [\"<end>\"] # добавление токенов старта (<start>) и конца (<end>)\n",
    "text = \" \".join(sequence) # собираем последовательность слов обратно в строку, но теперь даже служебные символы разделены пробелами\n",
    "encoded_text = tokenizer.texts_to_sequences([text]) # токенизируем текст\n",
    "padded_text = pad_sequences(encoded_text, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\", value=0) # приводим вектора токенов к единой размерности MAX_LEN с помощью padding_а и truncating_а (заполняем значением value)\n",
    "\n",
    "decoded_sentence = decode_sequence(padded_text)\n",
    "print(f\"Обработанный текст: {decoded_sentence}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
